train:
  batch_size: 16
  epochs: 35
  num_workers: 0
  restore_path: checkpoints/pretrain/checkpoint98
  save_path: checkpoints/finetune
  weight_decay: 0
  seed: 0
  num_run: 3
  lr: 0.0001
  scheduler:
    type: noam
    warmup_epochs: 2
    max_lr: 5e-4
    final_lr: 1e-4

test:
  test_interval: 1

data:
  data_dir: emegt/data/data/finetune
  split: scaffold


model:
  name: lipo
  hidden_dim: 64
  n_layers: 5
  layernorm: False
  n_heads: 8
  graph_pooling: mean
  dropout: 0
  no_pos_encod: False
  no_edge_update: False