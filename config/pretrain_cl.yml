train:
  batch_size: 32
  seed: 0
  epochs: 100
  num_workers: 8
  save: true
  save_path: checkpoints/pretrain
  log_interval: 100
  optimizer:
    type: Adam
    lr: 0.0001
    weight_decay: 0
  scheduler:
    type: expmin
    factor: 0.99
    min_lr: 0.00001

data:
  block_dir: datasets/pretrain

model:
  name: MolPGT
  hidden_dim: 64
  n_layers: 5
  n_heads: 8
  dropout: 0.0
  no_pos_encod: False
  no_edge_update: False